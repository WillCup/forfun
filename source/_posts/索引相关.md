
title: 索引相关
date: 2017-03-15 13:24:04
tags: [youdaonote]
---

- 哈希存储引擎

哈希表的持久化实现，支持增、删、改以及随机读取操作，但不支持顺序扫描，对应的存储系统为key-value存储系统。对于key-value的插入以及查询，哈希表的复杂度都是O(1)，明显比树的操作O(n)快,如果不需要有序的遍历数据，哈希表就是your Mr.Right

- B树存储引擎

不仅支持单条记录的增、删、读、改操作，还支持顺序扫描（B+树的叶子节点之间的指针），对应的存储系统就是关系数据库（Mysql等）。


- LSM树【Log-Structured Merge-Tree】

存储引擎和B树存储引擎一样，同样支持增、删、读、改、顺序扫描操作。而且通过批量存储技术规避磁盘随机写入问题。当然凡事有利有弊，LSM树和B+树相比，LSM树牺牲了部分读性能，用来大幅提高写性能。

==LSM树的设计思想==非常朴素：将对数据的修改增量保持在内存中，达到指定的大小限制后将这些修改操作批量写入磁盘，不过读取的时候稍微麻烦，需要合并磁盘中历史数据和内存中最近修改操作，所以写入性能大大提升，读取时可能需要先看是否命中内存，否则需要访问较多的磁盘文件。极端的说，基于LSM树实现的HBase的写性能比Mysql高了一个数量级，读性能低了一个数量级。

**LSM树原理把一棵大树拆分成N棵小树，它首先写入内存中，随着小树越来越大，内存中的小树会flush到磁盘中，磁盘中的树定期可以做merge操作，合并成一棵大树，以优化读性能.**

因为小树先写到内存中，为了防止内存数据丢失，写内存的同时需要暂时持久化到磁盘，对应了HBase的MemStore和HLog.

MemStore上的树达到一定大小之后，需要flush到HRegion磁盘中（一般是Hadoop DataNode），这样MemStore就变成了DataNode上的磁盘文件StoreFile，定期HRegionServer对DataNode的数据做merge操作，彻底删除无效空间，多棵小树在这个时机合并成大树，来增强读性能。


按照大小进行compact有三个缺点：
- 因为不能确定单行数据的版本都在哪里，所以无法保证一致性。最坏的情况下，每个sstable里都有一个某row的版本，分别包含不同的字段；
- 如果有大量删除操作的话，在merge以前很多数据的空间都是没有必要占用的；
- 在每个sstable在merge完成之前还是会占用很大的数据空间。最坏的情况就是，一个sstable并没有任何东西删除，那么Cassandra就使用同样大小的空间来进行compact操作。


Leveled Compaction
---

Leveled Compaction 创建相对小的固定大小的sstable(默认5M)，按照level分组。每层的sstable都不重复，每一层都是前一层的10倍大小。

解决了以上三个问题：
- level compaction保证90%的读请求只需要一个sstable里。最坏也就是每层有一个版本，加入10T数据，也就只有7个版本【10的7次方】
- 最多只有10%的空间浪费给要被删除的数据
- 每次只有10倍于sstable固定大小的空间被用于compaction的过程


由于level compaction上面的原理，相对于hbase 的基于大小的compaction，会有两倍的io。如果是以插入为主的系统，额外的io可能相对于上面的益处更严重一些，因为插入为主的话，还是很少出现row的相同版本的。

参考：
- http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.44.2782&rep=rep1&type=pdf
- http://www.cnblogs.com/yanghuahui/p/3483754.html
- http://www.open-open.com/lib/view/open1424916275249.html
- http://www.datastax.com/dev/blog/leveled-compaction-in-apache-cassandra
- http://hbasefly.com/2016/03/25/hbase-hfile/

