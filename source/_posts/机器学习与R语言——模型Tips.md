
title: 机器学习与R语言——模型Tips
date: 2017-02-09 14:21:36
tags: [youdaonote]
---

通用
=
对于NA缺失值的处理，连续型的可以给以均值、枚举型应该给一个unknown的计数。

距离类的算法，需要将各个特征进行标准化【z-score、max-min】

kmeans聚类
=
选择类的数量：根据业务判断

聚类结果的各类中的数量不应相差过于悬殊【也跟业务有关】

可以根据各个cluster中的特征z-score看出各个cluster自己的特性，并为之冠以业务名称。

模型性能评价
=
我们通常只用了分类结果，但是隐藏的概率没有看到。

例如，一个分类器可以同99%的把握确信包含“免费”和“铃声”等词语的短信是垃圾短信，但是只有51%的把握确信包含“今晚”的短信是垃圾短信。这两种情况都会被预测为垃圾短信，但是对两者做判断的确信程度就很大。一个是99，另一个才只有51，后者就极容易出现错误判断。
```
> head(subset(sms_results, actual_type != predict_type))
```

#### 混淆矩阵
通常使用二元的混淆矩阵：

准确率、错误率
kappa统计量
灵敏度（真阳性lv）、特异性（真阴性率）
精确度（阳性预测值）、召回率
F度量（综合精确度和召回率）

使用ROC曲线来可视化模型的可用性，ROC曲线是Y为真阳性比例、X为假阳性比例的线图。
AUC是ROC曲线下的面积，一般作为评价分类器的统计量。(Area Under the ROC)

#### 抽样
分层抽样：在从全量数据中抽取训练集或测试集的时候有个问题，就是每个类别中的数量可能过大或过小，因此我们应该从每个类别中按同样比例随机抽取数据。

K折交叉验证的方法默认就是使用分层抽样进行每次数据集的划分的。

较小数据集的时候，自助法抽样比K折的效果更好一些。


#### 提高模型的性能
可以使用caret进行自动参数调整，考虑三个问题：
- 需要使用数据来训练哪种机器学习模型
- 哪些模型参数是可以调整的，能调整的空间有多大
- 使用何种评价标准来评估模型从而找到最优的候选者
- 

朴素贝叶斯
=
假设数据集的所有特征都具有相同的重要性和独立性。


在贝叶斯算法中，概率值是相乘的，所以概率为0的值将导致该消息是垃圾邮件的后验概率为0.这种问题使用一种叫做拉普拉斯估计(Laplace estimator)的方法解决，本质上就是给频率表中的每个技术都加上一个较小的数，保证每一类中每个特征发生的概率是非零的。

决策树
=
boosting算法思想：通过将很多能力弱的学习算法组合在一起，就可以创建一个团队，这比任何一个单独学习算法都强的多。每个模型都有一组特定的优点和缺点，对于特定的问题，可能更好，也可能更差，而使用优缺互补的多种学习方法的结合，就可以显著提高分类器的准确性。

C5.0中是添加一个trials参数，表示在模型增强团队中使用的独立决策树的数量。trials设置了一个上限，如果该算法识别出额外的试验似乎没有提高模型准确性，那么它将停止添加决策树。

为啥默认不用boosting呢？一是时间因素，二是如果训练数据集很杂乱，那么boosting可能根本不会改善模型性能。


针对具体业务，设置风险矩阵cost matrix，添加到模型训练过程中，虽然整体预测准确率会降低，但是能够降低业务风险。

规则学习
=
规则学习经常以一种类似决策树学习的方式被使用。分类规则代表的是if-else逻辑语句形式的知识，可以用来对未标记的案例指定一个分类。

与决策树不同的是，决策树必须从上倒下地应用，而规则是单独存在的事实。根据相同数据建立的模型，规则学习的结果通常比决策树的结果更简洁、更直接、更容易理解。

规则学习擅长识别偶发事件。

决策树是分而治之，规则学习是独立而治之，区别是考虑决策节点的时候是否受过去决策历史的影响。

分类规则也可以直接从决策树获得。从一个叶子节点开始沿着树枝回到树根，就获得一系列的决策，这些决策可以组合成一个单一的规则。

当训练模型事，如果制定rules=TRUE,C5.0函数就利用分类规则生成模型了。


